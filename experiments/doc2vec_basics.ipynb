{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Following the tutorial at:\n",
    "# https://radimrehurek.com/gensim/auto_examples/tutorials/run_doc2vec_lee.html\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "import os\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data_dir is: \n",
      "/Users/minimal/detour-ai-ml/lib/python3.11/site-packages/gensim/test/test_data\n",
      "test corpuses include: \n",
      "head500.noblanks.cor\n",
      "varembed_lee_subcorpus.cor\n",
      "lee.cor\n",
      "pang_lee_polarity.cor\n",
      "miIslita.cor\n",
      "lee_background.cor\n"
     ]
    }
   ],
   "source": [
    "# directory that includes small corpuses for use in testing like this\n",
    "test_data_dir = os.path.join(gensim.__path__[0], 'test', 'test_data')\n",
    "print(f'test_data_dir is: \\n{test_data_dir}')\n",
    "print(f'test corpuses include: ')\n",
    "for file in os.listdir(test_data_dir):\n",
    "    if os.path.isfile(os.path.join(test_data_dir, file)):\n",
    "        if file.endswith('.cor'):\n",
    "            print(file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# The lee corpus contains a few hundred documents from an Australian news service\n",
    "lee_train_file = os.path.join(test_data_dir, 'lee_background.cor')\n",
    "# A much smaller corpus from the same source\n",
    "lee_test_file = os.path.join(test_data_dir, 'lee.cor')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "import smart_open\n",
    "\n",
    "def read_corpus(filename: str, token_only: bool=False):\n",
    "    # standard ASCII encoding\n",
    "    with smart_open.open(filename, encoding=\"iso-8859-1\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # tokenize each word, remove punctuation, remove cases\n",
    "            tokens = gensim.utils.simple_preprocess(line)\n",
    "            if token_only:\n",
    "                yield tokens\n",
    "            else:\n",
    "                yield gensim.models.doc2vec.TaggedDocument(tokens, [i])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_data = list(read_corpus(lee_train_file))\n",
    "test_data = list(read_corpus(lee_test_file))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TaggedDocument<['hundreds', 'of', 'people', 'have', 'been', 'forced', 'to', 'vacate', 'their', 'homes', 'in', 'the', 'southern', 'highlands', 'of', 'new', 'south', 'wales', 'as', 'strong', 'winds', 'today', 'pushed', 'huge', 'bushfire', 'towards', 'the', 'town', 'of', 'hill', 'top', 'new', 'blaze', 'near', 'goulburn', 'south', 'west', 'of', 'sydney', 'has', 'forced', 'the', 'closure', 'of', 'the', 'hume', 'highway', 'at', 'about', 'pm', 'aedt', 'marked', 'deterioration', 'in', 'the', 'weather', 'as', 'storm', 'cell', 'moved', 'east', 'across', 'the', 'blue', 'mountains', 'forced', 'authorities', 'to', 'make', 'decision', 'to', 'evacuate', 'people', 'from', 'homes', 'in', 'outlying', 'streets', 'at', 'hill', 'top', 'in', 'the', 'new', 'south', 'wales', 'southern', 'highlands', 'an', 'estimated', 'residents', 'have', 'left', 'their', 'homes', 'for', 'nearby', 'mittagong', 'the', 'new', 'south', 'wales', 'rural', 'fire', 'service', 'says', 'the', 'weather', 'conditions', 'which', 'caused', 'the', 'fire', 'to', 'burn', 'in', 'finger', 'formation', 'have', 'now', 'eased', 'and', 'about', 'fire', 'units', 'in', 'and', 'around', 'hill', 'top', 'are', 'optimistic', 'of', 'defending', 'all', 'properties', 'as', 'more', 'than', 'blazes', 'burn', 'on', 'new', 'year', 'eve', 'in', 'new', 'south', 'wales', 'fire', 'crews', 'have', 'been', 'called', 'to', 'new', 'fire', 'at', 'gunning', 'south', 'of', 'goulburn', 'while', 'few', 'details', 'are', 'available', 'at', 'this', 'stage', 'fire', 'authorities', 'says', 'it', 'has', 'closed', 'the', 'hume', 'highway', 'in', 'both', 'directions', 'meanwhile', 'new', 'fire', 'in', 'sydney', 'west', 'is', 'no', 'longer', 'threatening', 'properties', 'in', 'the', 'cranebrook', 'area', 'rain', 'has', 'fallen', 'in', 'some', 'parts', 'of', 'the', 'illawarra', 'sydney', 'the', 'hunter', 'valley', 'and', 'the', 'north', 'coast', 'but', 'the', 'bureau', 'of', 'meteorology', 'claire', 'richards', 'says', 'the', 'rain', 'has', 'done', 'little', 'to', 'ease', 'any', 'of', 'the', 'hundred', 'fires', 'still', 'burning', 'across', 'the', 'state', 'the', 'falls', 'have', 'been', 'quite', 'isolated', 'in', 'those', 'areas', 'and', 'generally', 'the', 'falls', 'have', 'been', 'less', 'than', 'about', 'five', 'millimetres', 'she', 'said', 'in', 'some', 'places', 'really', 'not', 'significant', 'at', 'all', 'less', 'than', 'millimetre', 'so', 'there', 'hasn', 'been', 'much', 'relief', 'as', 'far', 'as', 'rain', 'is', 'concerned', 'in', 'fact', 'they', 've', 'probably', 'hampered', 'the', 'efforts', 'of', 'the', 'firefighters', 'more', 'because', 'of', 'the', 'wind', 'gusts', 'that', 'are', 'associated', 'with', 'those', 'thunderstorms'], [0]>\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-30 17:48:03,765 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n5,w5,mc2,s0.001,t3>', 'datetime': '2023-03-30T17:48:03.764939', 'gensim': '4.3.1', 'python': '3.11.2 (main, Feb 16 2023, 03:15:23) [Clang 14.0.0 (clang-1400.0.29.202)]', 'platform': 'macOS-12.4-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "doc2vec_model = gensim.models.doc2vec.Doc2Vec(\n",
    "    vector_size=50,     # size of the vector embedding\n",
    "    min_count=2,        # only consider words that occur at least twice\n",
    "    epochs=40\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-30 17:53:57,926 : INFO : collecting all words and their counts\n",
      "2023-03-30 17:53:57,928 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-03-30 17:53:57,940 : INFO : collected 6981 word types and 300 unique tags from a corpus of 300 examples and 58152 words\n",
      "2023-03-30 17:53:57,941 : INFO : Creating a fresh vocabulary\n",
      "2023-03-30 17:53:57,954 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 3955 unique words (56.65% of original 6981, drops 3026)', 'datetime': '2023-03-30T17:53:57.954239', 'gensim': '4.3.1', 'python': '3.11.2 (main, Feb 16 2023, 03:15:23) [Clang 14.0.0 (clang-1400.0.29.202)]', 'platform': 'macOS-12.4-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2023-03-30 17:53:57,955 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 55126 word corpus (94.80% of original 58152, drops 3026)', 'datetime': '2023-03-30T17:53:57.955099', 'gensim': '4.3.1', 'python': '3.11.2 (main, Feb 16 2023, 03:15:23) [Clang 14.0.0 (clang-1400.0.29.202)]', 'platform': 'macOS-12.4-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2023-03-30 17:53:57,974 : INFO : deleting the raw counts dictionary of 6981 items\n",
      "2023-03-30 17:53:57,975 : INFO : sample=0.001 downsamples 46 most-common words\n",
      "2023-03-30 17:53:57,976 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 42390.98914085061 word corpus (76.9%% of prior 55126)', 'datetime': '2023-03-30T17:53:57.976178', 'gensim': '4.3.1', 'python': '3.11.2 (main, Feb 16 2023, 03:15:23) [Clang 14.0.0 (clang-1400.0.29.202)]', 'platform': 'macOS-12.4-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2023-03-30 17:53:57,978 : WARNING : sorting after vectors have been allocated is expensive & error-prone\n",
      "2023-03-30 17:53:58,012 : INFO : estimated required memory for 3955 words and 50 dimensions: 3679500 bytes\n",
      "2023-03-30 17:53:58,013 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "doc2vec_model.build_vocab(train_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3955\n"
     ]
    }
   ],
   "source": [
    "# .wv property contains the corpus\n",
    "print(len(doc2vec_model.wv)) # number of words in the corpus"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-30 17:56:51,439 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 3955 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-03-30T17:56:51.439966', 'gensim': '4.3.1', 'python': '3.11.2 (main, Feb 16 2023, 03:15:23) [Clang 14.0.0 (clang-1400.0.29.202)]', 'platform': 'macOS-12.4-x86_64-i386-64bit', 'event': 'train'}\n",
      "2023-03-30 17:56:51,493 : INFO : EPOCH 0: training on 58152 raw words (42693 effective words) took 0.0s, 903267 effective words/s\n",
      "2023-03-30 17:56:51,540 : INFO : EPOCH 1: training on 58152 raw words (42696 effective words) took 0.0s, 953061 effective words/s\n",
      "2023-03-30 17:56:51,590 : INFO : EPOCH 2: training on 58152 raw words (42743 effective words) took 0.0s, 913237 effective words/s\n",
      "2023-03-30 17:56:51,641 : INFO : EPOCH 3: training on 58152 raw words (42668 effective words) took 0.0s, 868123 effective words/s\n",
      "2023-03-30 17:56:51,693 : INFO : EPOCH 4: training on 58152 raw words (42636 effective words) took 0.0s, 855174 effective words/s\n",
      "2023-03-30 17:56:51,743 : INFO : EPOCH 5: training on 58152 raw words (42652 effective words) took 0.0s, 899210 effective words/s\n",
      "2023-03-30 17:56:51,799 : INFO : EPOCH 6: training on 58152 raw words (42798 effective words) took 0.1s, 788531 effective words/s\n",
      "2023-03-30 17:56:51,852 : INFO : EPOCH 7: training on 58152 raw words (42729 effective words) took 0.1s, 845418 effective words/s\n",
      "2023-03-30 17:56:51,908 : INFO : EPOCH 8: training on 58152 raw words (42641 effective words) took 0.1s, 800595 effective words/s\n",
      "2023-03-30 17:56:51,961 : INFO : EPOCH 9: training on 58152 raw words (42694 effective words) took 0.1s, 835437 effective words/s\n",
      "2023-03-30 17:56:52,014 : INFO : EPOCH 10: training on 58152 raw words (42715 effective words) took 0.0s, 860839 effective words/s\n",
      "2023-03-30 17:56:52,083 : INFO : EPOCH 11: training on 58152 raw words (42700 effective words) took 0.1s, 639416 effective words/s\n",
      "2023-03-30 17:56:52,135 : INFO : EPOCH 12: training on 58152 raw words (42741 effective words) took 0.0s, 860769 effective words/s\n",
      "2023-03-30 17:56:52,183 : INFO : EPOCH 13: training on 58152 raw words (42698 effective words) took 0.0s, 925048 effective words/s\n",
      "2023-03-30 17:56:52,235 : INFO : EPOCH 14: training on 58152 raw words (42805 effective words) took 0.0s, 872618 effective words/s\n",
      "2023-03-30 17:56:52,285 : INFO : EPOCH 15: training on 58152 raw words (42655 effective words) took 0.0s, 881113 effective words/s\n",
      "2023-03-30 17:56:52,329 : INFO : EPOCH 16: training on 58152 raw words (42628 effective words) took 0.0s, 1030181 effective words/s\n",
      "2023-03-30 17:56:52,372 : INFO : EPOCH 17: training on 58152 raw words (42670 effective words) took 0.0s, 1062558 effective words/s\n",
      "2023-03-30 17:56:52,414 : INFO : EPOCH 18: training on 58152 raw words (42636 effective words) took 0.0s, 1056886 effective words/s\n",
      "2023-03-30 17:56:52,457 : INFO : EPOCH 19: training on 58152 raw words (42620 effective words) took 0.0s, 1043997 effective words/s\n",
      "2023-03-30 17:56:52,502 : INFO : EPOCH 20: training on 58152 raw words (42685 effective words) took 0.0s, 983528 effective words/s\n",
      "2023-03-30 17:56:52,553 : INFO : EPOCH 21: training on 58152 raw words (42617 effective words) took 0.0s, 878356 effective words/s\n",
      "2023-03-30 17:56:52,603 : INFO : EPOCH 22: training on 58152 raw words (42614 effective words) took 0.0s, 889925 effective words/s\n",
      "2023-03-30 17:56:52,656 : INFO : EPOCH 23: training on 58152 raw words (42712 effective words) took 0.1s, 836253 effective words/s\n",
      "2023-03-30 17:56:52,713 : INFO : EPOCH 24: training on 58152 raw words (42705 effective words) took 0.1s, 781540 effective words/s\n",
      "2023-03-30 17:56:52,761 : INFO : EPOCH 25: training on 58152 raw words (42751 effective words) took 0.0s, 930674 effective words/s\n",
      "2023-03-30 17:56:52,803 : INFO : EPOCH 26: training on 58152 raw words (42725 effective words) took 0.0s, 1051619 effective words/s\n",
      "2023-03-30 17:56:52,846 : INFO : EPOCH 27: training on 58152 raw words (42728 effective words) took 0.0s, 1040417 effective words/s\n",
      "2023-03-30 17:56:52,888 : INFO : EPOCH 28: training on 58152 raw words (42721 effective words) took 0.0s, 1078122 effective words/s\n",
      "2023-03-30 17:56:52,930 : INFO : EPOCH 29: training on 58152 raw words (42689 effective words) took 0.0s, 1058916 effective words/s\n",
      "2023-03-30 17:56:52,972 : INFO : EPOCH 30: training on 58152 raw words (42697 effective words) took 0.0s, 1084498 effective words/s\n",
      "2023-03-30 17:56:53,013 : INFO : EPOCH 31: training on 58152 raw words (42668 effective words) took 0.0s, 1083037 effective words/s\n",
      "2023-03-30 17:56:53,060 : INFO : EPOCH 32: training on 58152 raw words (42642 effective words) took 0.0s, 951266 effective words/s\n",
      "2023-03-30 17:56:53,109 : INFO : EPOCH 33: training on 58152 raw words (42658 effective words) took 0.0s, 919789 effective words/s\n",
      "2023-03-30 17:56:53,163 : INFO : EPOCH 34: training on 58152 raw words (42614 effective words) took 0.1s, 835564 effective words/s\n",
      "2023-03-30 17:56:53,212 : INFO : EPOCH 35: training on 58152 raw words (42712 effective words) took 0.0s, 920003 effective words/s\n",
      "2023-03-30 17:56:53,253 : INFO : EPOCH 36: training on 58152 raw words (42679 effective words) took 0.0s, 1071842 effective words/s\n",
      "2023-03-30 17:56:53,296 : INFO : EPOCH 37: training on 58152 raw words (42667 effective words) took 0.0s, 1075001 effective words/s\n",
      "2023-03-30 17:56:53,337 : INFO : EPOCH 38: training on 58152 raw words (42647 effective words) took 0.0s, 1059857 effective words/s\n",
      "2023-03-30 17:56:53,379 : INFO : EPOCH 39: training on 58152 raw words (42747 effective words) took 0.0s, 1077456 effective words/s\n",
      "2023-03-30 17:56:53,380 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2326080 raw words (1707496 effective words) took 1.9s, 880627 effective words/s', 'datetime': '2023-03-30T17:56:53.380082', 'gensim': '4.3.1', 'python': '3.11.2 (main, Feb 16 2023, 03:15:23) [Clang 14.0.0 (clang-1400.0.29.202)]', 'platform': 'macOS-12.4-x86_64-i386-64bit', 'event': 'train'}\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "doc2vec_model.train(train_data, total_examples=doc2vec_model.corpus_count, epochs=doc2vec_model.epochs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.37315595 -0.1340146  -0.14571968 -0.01221686 -0.04597435 -0.06007713\n",
      "  0.06483229  0.1097223  -0.07305732 -0.07222687 -0.15381745 -0.04771632\n",
      " -0.16542223 -0.17817795 -0.28254053 -0.01174737  0.0885735  -0.04683914\n",
      "  0.0599751  -0.08511851  0.0641684   0.06057968  0.18171096  0.06763642\n",
      "  0.22661273 -0.1925833   0.02115663 -0.06181027  0.05923361 -0.03388556\n",
      "  0.12880793  0.2043309  -0.2736799   0.16304226 -0.0885709   0.1681882\n",
      "  0.14373718 -0.08547237  0.13269953 -0.03191527  0.05970052  0.12853006\n",
      " -0.03631823 -0.25596973  0.23304014  0.00889588  0.1405064  -0.09080721\n",
      "  0.02382964 -0.08414119]\n"
     ]
    }
   ],
   "source": [
    "# test the embedding of some text:\n",
    "def get_embedding(model: gensim.models.doc2vec.Doc2Vec, text: str):\n",
    "    tokens = gensim.utils.simple_preprocess(text)\n",
    "    return model.infer_vector(tokens)\n",
    "\n",
    "print(get_embedding(doc2vec_model, 'Hello, world!'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 300})\n"
     ]
    }
   ],
   "source": [
    "# Assessing the model\n",
    "ranks = []\n",
    "second_ranks = []\n",
    "for doc_id in range(len(train_data)):\n",
    "    embedding = doc2vec_model.infer_vector(train_data[doc_id].words)\n",
    "    sims = doc2vec_model.dv.most_similar([embedding], topn=len(doc2vec_model.dv))\n",
    "\n",
    "    rank = [doc_id for docid, sim in sims].index(doc_id) # find the rank of the original doc\n",
    "    ranks.append(rank)\n",
    "\n",
    "    second_ranks.append(sims[1])\n",
    "\n",
    "import collections\n",
    "counter = collections.Counter(ranks)\n",
    "print(counter)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document (299): «australia will take on france in the doubles rubber of the davis cup tennis final today with the tie levelled at wayne arthurs and todd woodbridge are scheduled to lead australia in the doubles against cedric pioline and fabrice santoro however changes can be made to the line up up to an hour before the match and australian team captain john fitzgerald suggested he might do just that we ll make team appraisal of the whole situation go over the pros and cons and make decision french team captain guy forget says he will not make changes but does not know what to expect from australia todd is the best doubles player in the world right now so expect him to play he said would probably use wayne arthurs but don know what to expect really pat rafter salvaged australia davis cup campaign yesterday with win in the second singles match rafter overcame an arm injury to defeat french number one sebastien grosjean in three sets the australian says he is happy with his form it not very pretty tennis there isn too many consistent bounces you are playing like said bit of classic old grass court rafter said rafter levelled the score after lleyton hewitt shock five set loss to nicholas escude in the first singles rubber but rafter says he felt no added pressure after hewitt defeat knew had good team to back me up even if we were down he said knew could win on the last day know the boys can win doubles so even if we were down still feel we are good enough team to win and vice versa they are good enough team to beat us as well»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec<dm/m,d50,n5,w5,mc2,s0.001,t3>:\n",
      "\n",
      "MOST (299, 0.9547232985496521): «australia will take on france in the doubles rubber of the davis cup tennis final today with the tie levelled at wayne arthurs and todd woodbridge are scheduled to lead australia in the doubles against cedric pioline and fabrice santoro however changes can be made to the line up up to an hour before the match and australian team captain john fitzgerald suggested he might do just that we ll make team appraisal of the whole situation go over the pros and cons and make decision french team captain guy forget says he will not make changes but does not know what to expect from australia todd is the best doubles player in the world right now so expect him to play he said would probably use wayne arthurs but don know what to expect really pat rafter salvaged australia davis cup campaign yesterday with win in the second singles match rafter overcame an arm injury to defeat french number one sebastien grosjean in three sets the australian says he is happy with his form it not very pretty tennis there isn too many consistent bounces you are playing like said bit of classic old grass court rafter said rafter levelled the score after lleyton hewitt shock five set loss to nicholas escude in the first singles rubber but rafter says he felt no added pressure after hewitt defeat knew had good team to back me up even if we were down he said knew could win on the last day know the boys can win doubles so even if we were down still feel we are good enough team to win and vice versa they are good enough team to beat us as well»\n",
      "\n",
      "SECOND-MOST (104, 0.8113467693328857): «australian cricket captain steve waugh has supported fast bowler brett lee after criticism of his intimidatory bowling to the south african tailenders in the first test in adelaide earlier this month lee was fined for giving new zealand tailender shane bond an unsportsmanlike send off during the third test in perth waugh says tailenders should not be protected from short pitched bowling these days you re earning big money you ve got responsibility to learn how to bat he said mean there no times like years ago when it was not professional and sort of bowlers code these days you re professional our batsmen work very hard at their batting and expect other tailenders to do likewise meanwhile waugh says his side will need to guard against complacency after convincingly winning the first test by runs waugh says despite the dominance of his side in the first test south africa can never be taken lightly it only one test match out of three or six whichever way you want to look at it so there lot of work to go he said but it nice to win the first battle definitely it gives us lot of confidence going into melbourne you know the big crowd there we love playing in front of the boxing day crowd so that will be to our advantage as well south africa begins four day match against new south wales in sydney on thursday in the lead up to the boxing day test veteran fast bowler allan donald will play in the warm up match and is likely to take his place in the team for the second test south african captain shaun pollock expects much better performance from his side in the melbourne test we still believe that we didn play to our full potential so if we can improve on our aspects the output we put out on the field will be lot better and we still believe we have side that is good enough to beat australia on our day he said»\n",
      "\n",
      "MEDIAN (12, 0.2410929650068283): «president general pervez musharraf says pakistan wants to defuse the brewing crisis with india but was prepared to respond vigorously to any attack pakistan stands for peace pakistan wants peace pakistan wants to reduce tension he said let the two countries move towards peace and harmony however pakistan has taken all counter measures if any war is thrust on pakistan the pakistan armed forces and the million people of pakistan are fully prepared to face all consequences with all their might the president said he had received the support of all political parties president musharraf also said he welcomed the intervention of the international community in trying to defuse the potentially explosive crisis we would like anybody to play useful and positive role in defusing the tension the united states the european union and the group of eight industrialised nations among others have all called on india and pakistan to exercise restraint and resolve the stand off through dialogue president musharraf repeated his offer of holding talks with indian prime minister atal behari vajpayee am for dialogue and keep on saying this and india keeps on rejecting which gives me feeling that am begging to india if they accept it we do not reject it at all he said on friday he said he was willing to meet prime minister vajpayee on the sidelines of the january south asian association for regional cooperation saarc summit in nepal india ruled out any face to face talks military tensions erupted between india and pakistan after the bloody december raid on the indian parliament india accuses pakistan military intelligence of masterminding the assault but pakistan denies the allegation with both countries massing troops along the border pakistan foreign minister abdul sattar warned saturday that the dispute was growing dangerously tense and any small act of provocation could snowball into conflict president musharraf said one of the goals of sunday meeting was to take stock of the internal situation the domestic environment want to eradicate militancy extremism intolerance from pakistani society and also said would like to eradicate any form of terrorism from the soil of pakistan however he warned the tension that has mounted on our eastern border in fact is creating obstacles and hurdles»\n",
      "\n",
      "LEAST (261, -0.11907856166362762): «afghan opposition leaders meeting in germany have reached an agreement after seven days of talks on the structure of an interim post taliban government for afghanistan the agreement calls for the immediate assembly of temporary group of multi national peacekeepers in kabul and possibly other areas the four afghan factions have approved plan for member ruling council composed of chairman five deputy chairmen and other members the council would govern afghanistan for six months at which time traditional afghan assembly called loya jirga would be convened to decide on more permanent structure the agreement calls for elections within two years»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Document ({}): «{}»\\n'.format(doc_id, ' '.join(train_data[doc_id].words)))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % doc2vec_model)\n",
    "for label, index in [('MOST', 0), ('SECOND-MOST', 1), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(train_data[sims[index][0]].words)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Document (51): «russian authorities have sentenced chechen warlord salman raduyev to life in prison for hostage siege in which more than people died salman raduyev is probably the most important chechen fighter russian authorities have ever caught relative of the first chechen president he was at the forefront of the insurgency leading raids against federal troops he was jealous of the achievements of his fellow commanders he resolved to outperform his rival and in january masterminded hostage taking in the neighbouring republic of dagestan apparently the aim was to destabilise dagestan and spread the war to the rest of the caucuses he ran out of luck as russian solders were not prepared to negotiate and cornered raduyev on the chechen border»\n",
      "\n",
      "Similar Document (141, 0.7087212800979614): «united states air strikes on al qaeda fighters have intensified following the collapse of surrender talks with the northern alliance the battle for tora bora appears to be heading towards bloody climax northern alliance commanders have now abandoned all attempts to secure peaceful surrender of al qaeda militants trapped in the mountainous area of tora bora truckloads of armed men have been seen heading toward the area suggesting full scale ground attack is imminent us aircraft have been bombarding the militants position since first light effectively blocking any possible retreat around pakistani troops have fanned across the border in bid to prevent any al qaeda fighters escaping»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training data\n",
    "# Pick a random document from the corpus and infer a vector from the model\n",
    "import random\n",
    "doc_id = random.randint(0, len(train_data) - 1)\n",
    "\n",
    "# Compare and print the second-most-similar document\n",
    "print('Train Document ({}): «{}»\\n'.format(doc_id, ' '.join(train_data[doc_id].words)))\n",
    "sim_id = second_ranks[doc_id]\n",
    "print('Similar Document {}: «{}»\\n'.format(sim_id, ' '.join(train_data[sim_id[0]].words)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Document (17): «the united nations world food program estimates that up to million people in seven countries malawi mozambique zambia angola swaziland lesotho and zimbabwe face death by starvation unless there is massive international response in malawi as many as people may have already died the signs of malnutrition swollen stomachs stick thin arms light coloured hair are everywhere»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER doc2vec_model Doc2Vec<dm/m,d50,n5,w5,mc2,s0.001,t3>:\n",
      "\n",
      "MOST (296, 0.7907843589782715): «today is world aids day and the latest figures show that million people are living with hiv world wide the latest united nations report on the aids epidemic has found eastern europe and the republics of the former soviet union are becoming the new battleground in the fight against the disease un officials say in russia the number of people carrying hiv doubles almost annually while ukraine has become the first nation in europe to report per cent of its adult population is hiv positive the officials say combination of economic insecurity high unemployment and deteriorating health services are behind the steep rise»\n",
      "\n",
      "MEDIAN (247, 0.4123954176902771): «the royal commission into hih has been adjourned until monday after interviewing of the first witness ended abruptly lawyers acting on behalf of several former hih directors requested that cross examination of david lombe and an inspector appointed by insurance watchdog the australian prudential regulation authority apra be held at later date the commission was due to hear evidence from mr lombe after the details of his report for apra were read in this morning hearing the report raises allegations that corporate governance was inadequate and concealed the true state of hih financial position the report questions the solvency of hih prior to it being placed into provisional liquidation on march it raises issues of intangible assets like tax and goodwill being treated as tangible for the acquisition of allianz to boost the financial position of hih the report also says significant losses by hih in the united states and the united kingdom were concealed from apra at meetings last year the commission has also heard apra had serious concerns about the accounting practices being followed by hih in july last year»\n",
      "\n",
      "LEAST (38, -0.0012549451785162091): «rafter who raised the alarm after most of his party was swept into the franklin river in tasmania south west says for nearly hours he did not know whether his four friends had survived richard romaszko was rafting down the collingwood river when the party was hit by huge water swell just before the junction with the franklin mr romaszko pulled himself to safety and after camping overnight he alerted tour group he was able to use the group satellite phone to raise the alarm second member of the party was found nearby yesterday afternoon while the other three were winched out by helicopter about pm aedt mr romanszko says he went into survival mode when we hit the bottom of the rapid there was big wave that overturned the rafts he said before we knew it we were in the franklin river at least my raft was upside down and the guy who was with me his raft was upside down»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing data\n",
    "# Pick a random document from the test corpus and infer a vector from the model\n",
    "doc_id = random.randint(0, len(test_data) - 1)\n",
    "inferred_vector = doc2vec_model.infer_vector(test_data[doc_id].words)\n",
    "sims = doc2vec_model.dv.most_similar([inferred_vector], topn=len(doc2vec_model.dv))\n",
    "\n",
    "# Compare and print the most/median/least similar documents from the train corpus\n",
    "print('Test Document ({}): «{}»\\n'.format(doc_id, ' '.join(test_data[doc_id].words)))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER doc2vec_model %s:\\n' % doc2vec_model)\n",
    "for label, index in [('MOST', 0), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(train_data[sims[index][0]].words)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "# Test the model trained with the small test corpus, on some examples\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def get_similarity(text1: str, text2: str)-> float:\n",
    "    embed1 = doc2vec_model.infer_vector(gensim.utils.simple_preprocess(text1))\n",
    "    embed2 = doc2vec_model.infer_vector(gensim.utils.simple_preprocess(text2))\n",
    "    # Cosine similarity\n",
    "    return dot(embed1, embed2)/(norm(embed1))/(norm(embed2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best for \"warm\" is \"Los Angeles Library\"\n",
      "best for \"knowledge\" is \"Los Angeles Library\"\n",
      "best for \"busy\" is \"NYC\"\n",
      "best for \"urban\" is \"Central Park\"\n"
     ]
    }
   ],
   "source": [
    "places={\n",
    "            \"NYC\":\n",
    "                \"The largest city in the United States.\",\n",
    "            \"Central Park\":\n",
    "                \"Central Park is an urban park in New York City. It is the fifth-largest park in the city. The park has natural-looking plantings and landforms, having been almost entirely landscaped when built in the 1850s and 1860s. It has eight lakes and ponds that were created artificially by damming natural seeps and flows.\",\n",
    "            \"Los Angeles Library\":\n",
    "                \"The Los Angeles Public Library provides free and easy access to information, ideas, books and technology that enrich, educate and empower every individual in our city's diverse communities.\"\n",
    "        }\n",
    "keywords = [\"warm\", \"knowledge\", \"busy\", \"urban\"]\n",
    "for keyword in keywords:\n",
    "    similarity = {place: get_similarity(places[place], keyword) for place in places.keys()}\n",
    "    best = max(places.keys(), key=lambda key: similarity[key])\n",
    "    print(f'best for \"{keyword}\" is \"{best}\"')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
